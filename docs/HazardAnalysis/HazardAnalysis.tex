\documentclass{article}

\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{hyperref}
\usepackage{pdflscape}

\hypersetup{
    colorlinks=true,       % false: boxed links; true: colored links
    linkcolor=red,          % color of internal links (change box color with linkbordercolor)
    citecolor=green,        % color of links to bibliography
    filecolor=magenta,      % color of file links
    urlcolor=cyan           % color of external links
}

\title{Hazard Analysis\\\progname}

\author{\authname}

\date{}

\input{../Comments}
\input{../Common}

\begin{document}

\maketitle
\thispagestyle{empty}

~\newpage

\pagenumbering{roman}

\begin{table}[hp]
\caption{Revision History} \label{TblRevisionHistory}
\begin{tabularx}{\textwidth}{llX}
\toprule
\textbf{Date} & \textbf{Developer(s)} & \textbf{Change}\\
\midrule
Oct 15 & SyntaxSentinels & Initial Revision\\
... & ... & ...\\
\bottomrule
\end{tabularx}
\end{table}

~\newpage

\tableofcontents

~\newpage

\pagenumbering{arabic}

\wss{You are free to modify this template.}

\section{Introduction}

% \wss{You can include your definition of what a hazard is here.}
A hazard is a property or condition in the system together with a condition in the environment that has the potential to cause harm, disrupt operations, 
or negatively affect the functionality of a system. Hazards can arise from various sources, including system 
malfunctions, human errors, environmental factors, or security vulnerabilities.

This document is the hazard analysis for the Capstone SyntaxSentinels. This project seeks to create a plagiarism algorithm that relies on NLP
techniques of present to account for semantics and prevent primitive circumvention of plagiarism detection, such as the addition of benign lines or
variable name changes.

\section{Scope and Purpose of Hazard Analysis}

The purpose of this hazard analysis is to identify, evaluate, and mitigate potential risks that could lead to system failures or undesired outcomes. In the context of this project, the primary losses incurred due to hazards could include:

\begin{itemize}
    \item Unauthorized interception of sensitive data, such as code submissions or plagiarism reports which could lead to privacy breaches.
    \item Misidentification of plagiarism cases, either false positives (innocent submissions flagged) or false negatives (plagiarized submissions unflagged).
    \item Disruption of service leading to user dissatisfaction, especially in time-sensitive code competition environments leading to loss of reputation.
    \item Inaccurate similarity scores, which could result in biased or incorrect decisions by professors or competition organizers.
\end{itemize}

The scope of this hazard analysis will cover the following areas:
\begin{itemize}
    \item Risks associated with data handling.
    \item Risks in the plagiarism detection algorithms and model performance.
    \item User authentication and access control risks.
    \item Potential human errors in adjusting plagiarism detection thresholds.
\end{itemize}

The analysis aims to minimize these risks and ensure the robustness, security, and accuracy of the system while maintaining a high level of user trust and system reliability.


\section{System Boundaries and Components}

\wss{Dividing the system into components will help you brainstorm the hazards.
You shouldn't do a full design of the components, just get a feel for the major
ones.  For projects that involve hardware, the components will typically include
each individual piece of hardware.  If your software will have a database, or an
important library, these are also potential components.}

\section{Critical Assumptions}
\begin{itemize}
    \item Adequate computational resources exist for the real time analysis of the code snippets
    \item Users do not intend to misuse the product
    \item Third party resources that support this product will always be functionally correct
    \item All components on the cloud will provide sufficient scalability and security
    \item The system will be maintained regularly with bug fixes/performance enhancements
    \item The criteria for plagiarism is agreed upon by all users
\end{itemize}

\section{Failure Mode and Effect Analysis}

\begin{landscape}
    \begin{table}[ht]
        \centering
        \scalebox{0.7}{ 
        \begin{tabular}{|p{1.75cm}|p{4cm}|p{5cm}|p{5cm}|p{3cm}|p{5cm}|p{2cm}|p{2cm}|}
        \hline
        \textbf{Design Function} & \textbf{Failure Modes} & \textbf{Effects of Failure} & \textbf{Causes of Failure} & \textbf{Detection} & \textbf{Recommended Actions} & \textbf{SR} & \textbf{Ref.} \\
        \hline
        Input Processing & Failure to tokenize text & Model fails to function or gives wrong output & a. Code not in Python \newline b. Tokenizer malfunction \newline c. Corrupted file & Check file extension to ensure .py suffix & a. Check input beforehand \newline b. Notify user of error occurred & & \\
        \cline{2-8}
        & Failure to upload file & Plagiarism detection process does not start & a. Invalid file type \newline b. Server error & Error handling & a. Notify user of failed upload & & \\
        \cline{2-8}
        \hline
        User Account Handling & Unauthorized access to account & a. Account compromised \newline b. User submissions compromised & a. Weak user authentication measures &  & a. Limit unsuccessful login attempts \newline  b. Multi-factor authentication & & \\
        \cline{2-8}
        \hline
        Result processing and generation & Model is overfitted & Model fails to identify plagiarism for many inputs & a. Small dataset \newline b. Dataset too specific  & Test model with test dataset & a. Ensure datasets don't all have similar code & & \\
        \cline{2-8}
        & Model providing false positives & Submissions incorrectly flagged for plagiarism & a. Inability to recognize common coding practices \newline b. Error in model & Proper tests with test data split & a. Implement good pattern analysis \newline b. Proper testing & & \\
        \cline{2-8}
        & Comments are tokenized or ignored incorrectly & Comments become extremely easy way to bypass plagiarism detection & a. Bad implementation of model \newline b. Error in code & Found in testing using inputs with comments & a. Ensure code handles comments properly & &\\
        \hline
        Result output display & Results e-mail failed to send & Users who close the tab will not see the results & a. Network issues on either sender/recipient side \ newline b. Blocked by spam filters \newline c. Incorrect e-mail address & & a. Send e-mail from safe and trusted domains b. Ensure recipient address is filled correctly in script & & \\
        \hline
        \end{tabular}
        } % End of \scalebox
        \caption{Failure Mode and Effect Analysis}
        \label{table:fmea}
    \end{table}
\end{landscape}
   

\section{Safety and Security Requirements}

\begin{itemize}
\item \textbf{SR-SAF1: Submission Rate Limitation}: The system shall limit the number of submissions by a parcitular user each day to prevent server overload.

Rationale: The activity of any user should not impact the performance of the system nor increase waiting times for other users.

\item \textbf{SR-SAF2: Safe System States During Failure}: In case of system error (i.e. hardware or network failures), the system shall inform users of the failure of their pending submissions before gracefully shutting down.

Rationale: This ensures that users are notified of submission failures, preventing confusion or wasted time.

\item \textbf{SR-SAF3: Warning of Potentially Inaccurate Detections}: In cases where the system produces detections with low confidence, the user shall be warned that the results may be inaccurate.

Rationale: Maintaining transparency that results may not be reliable protects users from acting on incorrect information before checking the results for themselves.

\item \textbf{SR-SAF4: Protection Against Inappropriate Inputs}: The system shall validate all user submissions and reject malformed code submissions.

Rationale: Malformed inputs could lead to system crashes, incorrect analysis, or compromise system performance.

\item \textbf{SR-SAF5: Isolation of Critical Functions}: Critical functions such as plagiarism detection and report generation shall be isolated from non-critical functionality to prevent faults in such non-critical components from affecting system stability.

Rationale: Issues in non-critical functions (such as the user interface) shouldn't compromise overall system stability.

\end{itemize}

\section{Roadmap}

\wss{Which safety requirements will be implemented as part of the capstone timeline?
Which requirements will be implemented in the future?}

\newpage{}

\section*{Appendix --- Reflection}

\wss{Not required for CAS 741}

\input{../Reflection.tex}

\begin{enumerate}
    \item What went well while writing this deliverable? 
    \item What pain points did you experience during this deliverable, and how
    did you resolve them?
    \item Which of your listed risks had your team thought of before this
    deliverable, and which did you think of while doing this deliverable? For
    the latter ones (ones you thought of while doing the Hazard Analysis), how
    did they come about?
    \item Other than the risk of physical harm (some projects may not have any
    appreciable risks of this form), list at least 2 other types of risk in
    software products. Why are they important to consider?
\end{enumerate}

\end{document}