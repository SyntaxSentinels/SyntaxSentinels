\documentclass{article}

\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{hyperref}
\usepackage{pdflscape}

\hypersetup{
    colorlinks=true,       % false: boxed links; true: colored links
    linkcolor=red,          % color of internal links (change box color with linkbordercolor)
    citecolor=green,        % color of links to bibliography
    filecolor=magenta,      % color of file links
    urlcolor=cyan           % color of external links
}

\title{Hazard Analysis\\\progname}

\author{\authname}

\date{}

\input{../Comments}
\input{../Common}

\begin{document}

\maketitle
\thispagestyle{empty}

~\newpage

\pagenumbering{roman}

\begin{table}[hp]
\caption{Revision History} \label{TblRevisionHistory}
\begin{tabularx}{\textwidth}{llX}
\toprule
\textbf{Date} & \textbf{Developer(s)} & \textbf{Change}\\
\midrule
Oct 15 & SyntaxSentinels & Initial Revision\\
... & ... & ...\\
\bottomrule
\end{tabularx}
\end{table}

~\newpage

\tableofcontents

~\newpage

\pagenumbering{arabic}

\wss{You are free to modify this template.}

\section{Introduction}

% \wss{You can include your definition of what a hazard is here.}
A hazard is a property or condition in the system together with a condition in the environment that has the potential to cause harm, disrupt operations, 
or negatively affect the functionality of a system. Hazards can arise from various sources, including system 
malfunctions, human errors, environmental factors, or security vulnerabilities.

This document is the hazard analysis for the Capstone SyntaxSentinels. This project seeks to create a plagiarism algorithm that relies on NLP
techniques of present to account for semantics and prevent primitive circumvention of plagiarism detection, such as the addition of benign lines or
variable name changes.

\section{Scope and Purpose of Hazard Analysis}

The purpose of this hazard analysis is to identify, evaluate, and mitigate potential risks that could lead to system failures or undesired outcomes. In the context of this project, the primary losses incurred due to hazards could include:

\begin{itemize}
    \item Unauthorized interception of sensitive data, such as code submissions or plagiarism reports which could lead to privacy breaches.
    \item Misidentification of plagiarism cases, either false positives (innocent submissions flagged) or false negatives (plagiarized submissions unflagged).
    \item Disruption of service leading to user dissatisfaction, especially in time-sensitive code competition environments leading to loss of reputation.
    \item Inaccurate similarity scores, which could result in biased or incorrect decisions by professors or competition organizers.
\end{itemize}

The scope of this hazard analysis will cover the following areas:
\begin{itemize}
    \item Risks associated with data handling.
    \item Risks in the plagiarism detection algorithms and model performance.
    \item User authentication and access control risks.
    \item Potential human errors in adjusting plagiarism detection thresholds.
\end{itemize}

The analysis aims to minimize these risks and ensure the robustness, security, and accuracy of the system while maintaining a high level of user trust and system reliability.


\section{System Boundaries and Components}

\wss{Dividing the system into components will help you brainstorm the hazards.
You shouldn't do a full design of the components, just get a feel for the major
ones.  For projects that involve hardware, the components will typically include
each individual piece of hardware.  If your software will have a database, or an
important library, these are also potential components.}

\section{Critical Assumptions}
\begin{itemize}
    \item Adequate computational resources exist for the real time analysis of the code snippets
    \item Users do not intend to misuse the product
    \item Third party resources that support this product will always be functionally correct
    \item All components on the cloud will provide sufficient scalability and security
    \item The system will be maintained regularly with bug fixes/performance enhancements
    \item The criteria for plagiarism is agreed upon by all users
\end{itemize}

\section{Failure Mode and Effect Analysis}

\begin{landscape}
    \begin{table}[ht]
        \centering
        \scalebox{0.7}{ 
        \begin{tabular}{|p{1.75cm}|p{4cm}|p{5cm}|p{5cm}|p{3cm}|p{5cm}|p{2cm}|p{2cm}|}
        \hline
        \textbf{Design Function} & \textbf{Failure Modes} & \textbf{Effects of Failure} & \textbf{Causes of Failure} & \textbf{Detection} & \textbf{Recommended Actions} & \textbf{SR} & \textbf{Ref.} \\
        \hline
        Input Processing & Failure to tokenize text & Model fails to function or gives wrong output & a. Code not in Python \newline b. Tokenizer malfunction \newline c. Corrupted file & Check file extension to ensure .py suffix & a. Check input beforehand \newline b. Notify user of error occurred & & \\
        \cline{2-8}
        & Failure to upload file & Plagiarism detection process does not start & a. Invalid file type \newline b. Server error & Error handling & a. Notify user of failed upload & & \\
        \cline{2-8}
        \hline
        User Account Handling & Unauthorized access to account & a. Account compromised \newline b. User submissions compromised & a. Weak user authentication measures &  & a. Limit unsuccessful login attempts \newline  b. Multi-factor authentication & & \\
        \cline{2-8}
        \hline
        Result processing and generation & Model is overfitted & Model fails to identify plagiarism for many inputs & a. Small dataset \newline b. Dataset too specific  & Test model with test dataset & a. Ensure datasets don't all have similar code & & \\
        \cline{2-8}
        & Model providing false positives & Submissions incorrectly flagged for plagiarism & a. Inability to recognize common coding practices \newline b. Error in model & Proper tests with test data split & a. Implement good pattern analysis \newline b. Proper testing & & \\
        \cline{2-8}
        & Comments are tokenized or ignored incorrectly & Comments become extremely easy way to bypass plagiarism detection & a. Bad implementation of model \newline b. Error in code & Found in testing using inputs with comments & a. Ensure code handles comments properly & &\\
        \hline
        Result output display & Results e-mail failed to send & Users who close the tab will not see the results & a. Network issues on either sender/recipient side \ newline b. Blocked by spam filters \newline c. Incorrect e-mail address & & a. Send e-mail from safe and trusted domains b. Ensure recipient address is filled correctly in script & & \\
        \hline
        \end{tabular}
        } % End of \scalebox
        \caption{Failure Mode and Effect Analysis}
        \label{table:fmea}
    \end{table}
\end{landscape}
   

\section{Safety and Security Requirements}

\begin{itemize}
\item \label{req:saf1} \textbf{SR-SAF1: Submission Rate Limitation}: The system shall limit the number of submissions by a parcitular user each day to prevent server overload.

Rationale: The activity of any user should not impact the performance of the system nor increase waiting times for other users.

\item \label{req:saf2} \textbf{SR-SAF2: Safe System States During Failure}: In case of system error (i.e. hardware or network failures), the system shall inform users of the failure of their pending submissions before gracefully shutting down.

Rationale: This ensures that users are notified of submission failures, preventing confusion or wasted time.

\item \label{req:saf3} \textbf{SR-SAF3: Warning of Potentially Inaccurate Detections}: In cases where the system produces detections with low confidence, the user shall be warned that the results may be inaccurate.

Rationale: Maintaining transparency that results may not be reliable protects users from acting on incorrect information before checking the results for themselves.

\item \label{req:saf4} \textbf{SR-SAF4: Protection Against Inappropriate Inputs}: The system shall validate all user submissions and reject malformed code submissions.

Rationale: Malformed inputs could lead to system crashes, incorrect analysis, or compromise system performance.

\item \label{req:saf5} \textbf{SR-SAF5: Isolation of Critical Functions}: Critical functions such as plagiarism detection and report generation shall be isolated from non-critical functionality to prevent faults in such non-critical components from affecting system stability.

Rationale: Issues in non-critical functions (such as the user interface) shouldn't compromise overall system stability.

\end{itemize}

\section{Roadmap}

This section outlines the implementation timeline for the safety and security requirements of the project. The following safety requirements will be prioritized and implemented as part of the capstone timeline, while others may be deferred for future releases to ensure complete and secure functionality.

\subsection{Capstone Timeline Implementation}

\begin{itemize}
    \item \textbf{\hyperref[req:saf1]{SR-SAF1: Submission Rate Limitation}}
    \begin{itemize}
        \item \textbf{Description}: The system shall limit the number of submissions by a particular user each day to prevent server overload.
        \item \textbf{Rationale}: To ensure the system maintains optimal performance and prevents any user from monopolizing system resources.
        \item \textbf{Implementation Plan}: This will be implemented early on to mitigate any risks of server performance issues.
    \end{itemize}

    \item \textbf{\hyperref[req:saf2]{SR-SAF2: Safe System States During Failure}}
    \begin{itemize}
        \item \textbf{Description}: The system shall inform users of submission failures due to hardware or network errors and gracefully shut down.
        \item \textbf{Rationale}: Ensuring users are informed of system failures protects them from being left in the dark regarding their submissions.
        \item \textbf{Implementation Plan}: This feature will be crucial to handle system stability and to improve user experience, making it a priority during development.
    \end{itemize}

    \item \textbf{\hyperref[req:saf4]{SR-SAF4: Protection Against Inappropriate Inputs}}
    \begin{itemize}
        \item \textbf{Description}: The system shall validate all user submissions and reject malformed code submissions.
        \item \textbf{Rationale}: Prevents system crashes, incorrect analysis, or compromised performance due to malformed inputs.
        \item \textbf{Implementation Plan}: Will be integrated during the core system development phase to safeguard against harmful inputs.
    \end{itemize}

    \item \textbf{\hyperref[req:saf5]{SR-SAF5: Isolation of Critical Functions}}
    \begin{itemize}
        \item \textbf{Description}: Critical functions (plagiarism detection, report generation) shall be isolated from non-critical functions (UI) to prevent faults from spreading.
        \item \textbf{Rationale}: Ensures that non-essential issues do not impact the core stability of the system.
        \item \textbf{Implementation Plan}: This is critical for maintaining the integrity of the plagiarism detection system and will be developed alongside the primary features.
    \end{itemize}
\end{itemize}

\subsection{Future Releases}

\begin{itemize}
    \item \textbf{\hyperref[req:saf3]{SR-SAF3: Warning of Potentially Inaccurate Detections}}
    \begin{itemize}
        \item \textbf{Description}: The system shall warn users if detections have low confidence levels and could be inaccurate.
        \item \textbf{Rationale}: To maintain transparency with users, ensuring they do not rely on potentially incorrect results without further verification.
        \item \textbf{Future Implementation Plan}: This feature will be added after the initial release, once the confidence scoring mechanism has been thoroughly tested and refined.
    \end{itemize}
\end{itemize}

This roadmap ensures that the essential safety requirements are delivered as part of the capstone project, with further refinements and advanced features to be implemented in future iterations.

\newpage{}

\section*{Appendix --- Reflection}

\wss{Not required for CAS 741}

\input{../Reflection.tex}

\begin{enumerate}
    \item What went well while writing this deliverable? 

    Ascertaining what our system boundary was went particularly well. It had 
    us become confident in what development will require of us along with 
    where hazards could occur. Carefully reflecting on this made the rest 
    of the deliverable smoother since we could isolate components instead of 
    attempting to inspect the entirety of our project at once. It ultimately 
    had our team unify further on how we potentially can implement aspects of
    our product, giving a clearer vision for the development.
    Also, Coming up with new safety and security requirements was made easier by
    defining the system boundary and FMEA table. After taking a step back, some
    hazards are easier to spot, and requiements to mitigate them become more obvious.

    \item What pain points did you experience during this deliverable, and how
    did you resolve them?

    It was unclear at first how to reconcile requirements made in this document
    with our SRS, such as if we had to add them in on the SRS document in a
    new section. We resolved this by clarifying with the TA during our meeting
    for this deliverable. We also were unsure about the timeline of
    implementation of our requirements to address identified hazards. It was
    not fully clear what would be realistic. We addressed this using our 
    intuition by giving what we thought were fair priorities to each
    hazard, and ordering the addressal of hazards based on these priorities.
    We also kept the timings a little broad to give us breathing room incase 
    something changes.
    Finally, It was somewhat challenging for us to agree on some assumptions we made
    when creating our system boundaries. This is because our project does not provide
    a service, and only gives code for users to set up on their own infrastructure.
    If we provided our product as a service as well, we would have to consider more
    hazards that come with hosting (and communitaction between) servers.

    \item Which of your listed risks had your team thought of before this
    deliverable, and which did you think of while doing this deliverable? For
    the latter ones (ones you thought of while doing the Hazard Analysis), how
    did they come about?
    
    Old ones: model providing false positives, failure to upload file, 
    model is overfitted, Unauthorized access to account
    \\
    New ones: results in email failed to send, failure to tokenize text, 
    Comments are tokenized or ignored incorrectly
    \\
    The new ones came about mainly thanks to the components identified in the 
    system boundary. Before, we did not isolate the parser in its functionality 
    from the model itself nor did we think about adversarial ways to trick the 
    parser, such as comments. We also didn't consider the output failing to 
    reach the user, and this was identified thanks to an exercise where we 
    asked all ways output could reach a user and found we originally just
    thought about the ways the threshold scores could be erroneously displayed.
    

    \item Other than the risk of physical harm (some projects may not have any
    appreciable risks of this form), list at least 2 other types of risk in
    software products. Why are they important to consider?

    Security Risks - Since our product deals with sensitive user data (user code
    submissions and generated plagiarism detection reports), it is important to
    consider the security of that data.

    Performance Risks - Our product requires a lot of computational power to function,
    and given that we plan to support multiple users using our service concurrently, ensuring
    that one user's usage does not negatively impact the experience of other users is important.


\end{enumerate}

\end{document}