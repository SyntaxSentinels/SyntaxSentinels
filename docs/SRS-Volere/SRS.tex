% THIS DOCUMENT IS FOLLOWS THE VOLERE TEMPLATE BY Suzanne Robertson and James Robertson
% ONLY THE SECTION HEADINGS ARE PROVIDED
%
% Initial draft from https://github.com/Dieblich/volere
%
% Risks are removed because they are covered by the Hazard Analysis
\documentclass[12pt]{article}

\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{hyperref}
\hypersetup{
    bookmarks=true,         % show bookmarks bar?
      colorlinks=true,      % false: boxed links; true: colored links
    linkcolor=red,          % color of internal links (change box color with linkbordercolor)
    citecolor=green,        % color of links to bibliography
    filecolor=magenta,      % color of file links
    urlcolor=cyan           % color of external links
}

\newcommand{\lips}{\textit{Insert your content here.}}

\input{../Comments}
\input{../Common}

\begin{document}

\title{Software Requirements Specification for \progname: Code Plagiarism Detector} 
\author{\authname}
\date{\today}
	
\maketitle

~\newpage

\pagenumbering{roman}

\tableofcontents

~\newpage

\section*{Revision History}

\begin{tabularx}{\textwidth}{p{3cm}p{2cm}X}
\toprule {\textbf{Date}} & {\textbf{Version}} & {\textbf{Notes}}\\
\midrule
October 9 & 1.0 & First iteration of complete document\\
% Date 2 & 1.1 & Notes\\
\bottomrule
\end{tabularx}

~\\

~\newpage
\section{Purpose of the Project}
\subsection{User Business}
\lips
\subsection{Goals of the Project}
\lips

\section{Stakeholders}

\subsection{Client}
The primary clients for this project are the computing and software departments
of academic institutions, and code competition administrators. These clients
seek an advanced plagiarism detection system that overcomes the limitations of
existing tools like MOSS. In academic settings, the system will help maintain
academic integrity, while in code competitions, it will ensure fair play by
preventing plagiarism among participants.

\subsection{Customer}
The primary customers for this project are professors, course instructors, and
code competition organizers. Professors and instructors will use the system to
evaluate student submissions to identify plagiarism, while competition
organizers will ensure that all participants submit original code. 

\subsection{Other Stakeholders}
Other stakeholders include:
\begin{itemize}
    \item Students: Indirectly affected, as their work will be evaluated by this
    system, and it is important to ensure that students don't get falsely accused
    of plagiarism.
    \item Competition Participants: In coding competitions, the participants
    rely on the system to ensure the competition they participate in is fair.
\end{itemize}

\subsection{Hands-On Users of the Project}
The hands-on users are the professors, teaching assistants, and code competition
organizers who will directly interact with the system. They will use it to
upload code submissions, compare entries, and review plagiarism reports.

\subsection{Personas}
\begin{itemize}
    \item Professor: Dr.\ Onjama Wembo - A computer science professor who
    frequently assigns coding tasks and reviews student submissions.
    \item Student: John Johnson - An honest computer science student who
    expects the system to verify their work as valid and unplagiarised.
    \item Competition Organizer: Sung Yuhee - A competition organizer who
    uses the system to ensure participants submit original work to ensure fair
    play in the competition.
    \item Competition Participant: Giorno Capio - A competition participant
    aiming for a top score in the competition, who is hoping the system does not
    misclassify their work with someone elses who may have similar code.
\end{itemize}

\subsection{Priorities Assigned to Users}
\begin{itemize}
    \item High Priority: Professors, competition organizers, and instructors -
    They rely on the system to evaluate submissions to ensure integrity
    \item Low Priority: Students and competition participants - They are not the
    direct users of the system but rely on it for correct evaluations
\end{itemize}

\subsection{User Participation}
User participation is essential for the development and testing of the system.
Professors will provide feedback during development and testing to ensure the
system meets their needs. Regular feedback will help improve the system's
accuracy and reliability.

\subsection{Maintenance Users and Service Technicians}
If possible, system administrators and IT staff will maintain the system. They
will troubleshoot issues to keep the system functional, as well as oversee
updates to the system.

\section{Mandated Constraints}
\subsection{Solution Constraints}
\lips
\subsection{Implementation Environment of the Current System}
\lips
\subsection{Partner or Collaborative Applications}
\lips
\subsection{Off-the-Shelf Software}
\lips
\subsection{Anticipated Workplace Environment}
\lips
\subsection{Schedule Constraints}
\lips
\subsection{Budget Constraints}
\lips
\subsection{Enterprise Constraints}
\lips

\section{Naming Conventions and Terminology}
\subsection{Glossary of All Terms, Including Acronyms, Used by Stakeholders
involved in the Project}
\lips

\section{Relevant Facts And Assumptions}
\subsection{Relevant Facts}
\begin{itemize}
  \item The current standard for code plagiarism detection, MOSS, primarily relies on token matching and syntax-based comparison. This method lacks the ability to detect deeper semantic similarities in code.
  \item NLP techniques have advanced significantly in recent years, enabling more accurate natural language understanding. These techniques can be adapted to understand the structure and semantics of code, which could enhance plagiarism detection systems.
  \item There is a growing need for a plagiarism detection system that accounts for sophisticated plagiarism techniques, such as variable renaming, code restructuring, and adding non-functional code.
  \item Academic institutions are increasingly concerned with the fairness and accuracy of plagiarism detection systems to avoid penalizing students unfairly, especially with the rising prevalence of online and remote learning.
\end{itemize}
\subsection{Business Rules}
\begin{itemize}
  \item The system must ensure compliance with data protection regulations, such as GDPR, by securing student data, anonymizing it when possible, and minimizing unnecessary data retention.
  \item The similarity threshold for flagging plagiarism should be customizable by the institution or professor, allowing flexibility based on course policies.
  \item False positives (e.g., common code patterns) should be minimized, with options for professors to override flagged instances and manually validate the results.
  \item The system must be scalable to accommodate large datasets and multiple users submitting code for comparison at the same time.
\end{itemize}
\subsection{Assumptions}
\begin{itemize}
  \item It is assumed that the academic institutions adopting this system have clear plagiarism policies and can provide a threshold score that reflects their definitions of plagiarism.
  \item It is assumed that the code samples provided for comparison are original and not previously processed by other plagiarism detection systems, ensuring that the results reflect real-time analysis.
  \item It is assumed that professors and administrators will review flagged cases manually to confirm plagiarism before taking any disciplinary action.
  \item It is assumed that students will not have access to the internal workings of the plagiarism detection algorithm, preventing them from finding potential loopholes to bypass detection.
  \item Software will be used only in Canada, and the legal and ethical considerations of this country will be taken into account during development.
\end{itemize}

\section{The Scope of the Work}
\subsection{The Current Situation}
The current code plagiarism dtection tools such as MOSS rely on tokenization and syntax-level comparisons. Although effective
in detecting direct copies or slight variations, they struggle when faced with techniques such as adding redundant code which
allows the user to completely bypass detection while still plagiarizing the underlying logic and structure of the code.

Additionally, MOSS does not take into account for the complexity or intent behind the code, leading to issues such as false
positives for common programming patterns. This creates a gap for more advanced tools capable of understanding the semantic 
meaning of code to more accurately detect plagiarism.
\subsection{The Context of the Work}
Our project aims to address these gaps by incorporating Natural Language Processing (NLP) and machine learning techniques
which will be leveraged to improve the accuracy of detecting copied code. The context of the work is within academic institutions,
where the integrity of student work is aparmount and our tool will be used by professors to ensure a fair grading process
while also supporting students in understanding the ethical use of code.
\subsection{Work Partitioning}
\begin{itemize}
  \item \textbf{Research and Design}: Conduct research on current plagiarism detection systems and state-of-the-art NLP techniques applicable to code plagiarism.
  
  \item \textbf{Data Collection}: Gather a dataset of code snippets, including both plagiarized and original works, to train and test the model.
  
  \item \textbf{Model Development}: Develop the NLP-based model capable of understanding the semantic meaning of code. This may involve exploring techniques like abstract syntax trees (ASTs), vector embeddings, or other representations of code that retain semantic meaning.
  
  \item \textbf{System Integration}: Build the system to take code as input, run through the developed model, and output a similarity score with appropriate thresholds.
  
  \item \textbf{Testing and Validation}: Test the system with various code samples to validate its performance and accuracy compared to traditional systems like MOSS. This will also test whether our method produces any false positives.
  
  \item \textbf{Documentation and Deployment}: Document the system architecture, the model, and the results. Deploy the system for use within academic settings.
\end{itemize}
\subsection{Specifying a Business Use Case (BUC)}

\textbf{Business Use Case:} Automated Code Plagiarism Detection for Academic Institutions

\begin{itemize}
    \item \textbf{Actors:} Professors, Students, System Administrators
    \item \textbf{Trigger:} A professor or system administrator uploads multiple code submissions for plagiarism detection in a course assignment.
\end{itemize}

\textbf{Main Success Scenario}
\begin{enumerate}
    \item The system ingests the uploaded code submissions.
    \item The system processes each code snippet using the NLP model to generate semantic representations of the code.
    \item The system compares the representations to detect plagiarism, taking into account code similarity beyond syntax or token matching.
    \item The system outputs a similarity score for each comparison, with thresholds indicating whether plagiarism is suspected.
    \item The professor reviews the similarity scores and flags any suspicious cases for further investigation.
    \item The system generates a report summarizing the findings for the professor’s review.
\end{enumerate}

\textbf{Extensions}
\begin{itemize}
    \item If the system detects false positives (common programming patterns being flagged as plagiarism), the professor can override the result.
    \item If new sophisticated plagiarism techniques are detected, the system can update its learning algorithms to improve accuracy over time.
\end{itemize}

\section{Business Data Model and Data Dictionary}
\subsection{Business Data Model}
\lips
\subsection{Data Dictionary}
\lips

\section{The Scope of the Product}
\subsection{Product Boundary}
\lips
\subsection{Product Use Case Table}
\lips
\subsection{Individual Product Use Cases (PUC's)}
\lips

\section{Functional Requirements}
\subsection{Functional Requirements}
\begin{itemize}
    \item The system will take in code snippets as inputs
    \item The system must parse the input into a format that can be fed into a model for interpretation
    \item The system will leverage known natural language processing techniques to handle inputs
    \item The system will process the formatted input to provide a verdict on the presence of plagiarism as output
    \item The system must generate clear and concise outputs to indicate plagiarism
    \item The system's outputs should provide explanations on how to interpret output
\end{itemize}

\section{Look and Feel Requirements}

\subsection{Appearance Requirements}
The user interface (UI) must adhere to the following appearance guidelines:
\begin{itemize}
    \item \textbf{Consistency}: The UI should maintain a uniform color palette, 
    font, and layout across all screens and elements. For instance, the primary 
    color is defined as blue (\#0047AB) for buttons, links, and headers, and 
    white (\#FFFFFF) for background areas.
    
    \item \textbf{Clarity}: All icons, buttons, and menus should be intuitive and 
    clearly identifiable. Hovering over icons will provide tooltips with a brief 
    description of their functionality.
    
    \item \textbf{Responsiveness}: The layout should adjust according to screen 
    size, ensuring the interface remains usable on a range of devices, including 
    desktops, tablets, and mobile phones.
\end{itemize}

\subsection{Style Requirements}
The style guidelines for the interface are as follows:
\begin{itemize}
    \item \textbf{Typography}: The font family used across the UI will be 
    \textit{Roboto}. Headers should use a 24px font size, body text should be 
    14px, and button text should be 16px.
    
    \item \textbf{Color Scheme}: Buttons and interactive elements should use the 
    primary color \#0047AB. Background areas will use \#F0F0F0, and error 
    messages will be highlighted in \#FF0000.
    
    \item \textbf{Button Styles}: All buttons should have rounded corners with 
    a radius of 5px. On hover, the button background will lighten by 20\%.
    
    \item \textbf{Spacing and Padding}: There should be at least 10px of padding 
    between elements and a margin of 20px around each section to maintain a clean 
    layout.
\end{itemize}


\section{Usability and Humanity Requirements}

\subsection{Ease of Use Requirements}
The system should be intuitive and simple to use for the target audience.
\begin{itemize}
    \item \textbf{Minimal Learning Curve}: Users should be able to complete tasks 
    with minimal instruction or training, taking at most 5 minutes from start 
    to finish. The interface must guide users intuitively through this process.
    
    \item \textbf{Task Efficiency}: Common tasks should be achievable in no more 
    than three clicks or interactions from the main screen.
    
    \item \textbf{Clear Navigation}: All navigation elements should be labeled 
    clearly and positioned consistently across different pages to avoid confusion.
\end{itemize}

\subsection{Personalization and Internationalization Requirements}
The system will support a customizable experience in the future, but users will 
not be able to modify key settings such as themes or layout preferences at launch.
\begin{itemize}
    \item \textbf{Future Customization Support}: Future updates will allow users 
    to modify settings such as themes and layouts to suit their personal preferences.
    
    \item \textbf{English Language Support}: The system will operate exclusively 
    in English, with all dates, currency, and numeric formats adhering to 
    English (US) standards.
\end{itemize}

\subsection{Learning Requirements}
The system should provide clear documentation and onboarding materials.
\begin{itemize}
    \item \textbf{Onboarding}: A guided onboarding process should be available 
    for new users, helping them understand the main features of the system 
    in under 5 minutes.
    
    \item \textbf{Help Documentation}: Detailed help documentation and tooltips 
    should be available for key features to reduce the need for external 
    assistance.
\end{itemize}

\subsection{Understandability and Politeness Requirements}
The system should use clear language and maintain a polite tone in all 
interactions with users.
\begin{itemize}
    \item \textbf{Clear Language}: All messages and labels should be in simple, 
    everyday language to ensure clarity for users of different levels of 
    technical expertise.
    
    \item \textbf{Politeness}: Error messages and prompts should be worded 
    politely and offer constructive guidance. Example error messages include:
    \begin{itemize}
        \item \textit{“Oops! Something went wrong. Please try again or contact 
        support if the issue persists.”}
        \item \textit{“We're sorry, but the file you uploaded is not supported. 
        Please upload a .py file.”}
    \end{itemize}
\end{itemize}

\subsection{Accessibility Requirements}
Due to time constraints, the system will not be fully accessible at launch. But this can be a future goal.

\section{Performance Requirements}
\subsection{Speed and Latency Requirements}
\lips
\subsection{Safety-Critical Requirements}
\lips
\subsection{Precision or Accuracy Requirements}
\lips
\subsection{Robustness or Fault-Tolerance Requirements}
\lips
\subsection{Capacity Requirements}
\lips
\subsection{Scalability or Extensibility Requirements}
\lips
\subsection{Longevity Requirements}
\lips

\section{Operational and Environmental Requirements}
\subsection{Expected Physical Environment}
\lips
\subsection{Wider Environment Requirements}
\lips
\subsection{Requirements for Interfacing with Adjacent Systems}
\lips
\subsection{Productization Requirements}
\lips
\subsection{Release Requirements}
\lips

\section{Maintainability and Support Requirements}
\subsection{Maintenance Requirements}
\lips
\subsection{Supportability Requirements}
\lips
\subsection{Adaptability Requirements}
\lips

\section{Security Requirements}
\subsection{Access Requirements}
\lips
\subsection{Integrity Requirements}
\lips
\subsection{Privacy Requirements}
\lips
\subsection{Audit Requirements}
\lips
\subsection{Immunity Requirements}
\lips

\section{Cultural Requirements}
\subsection{Cultural Requirements}
No major cultural requirements are identified for this project but some that could be taken into consideration are:\\ \\ 
\noindent \textbf{Data Privacy and Ethical Use}\\ 
\textbf{Student Privacy}: In some cultures and institutions, the handling of student work and data is highly regulated. Laws like the FIPPA mandate strict data privacy standards. The system should ensure that student data, including their code submissions, is securely handled, anonymized where possible, and not stored unnecessarily.
\\ \\
\noindent \textbf{Differences in Academic Integrity Norms}\\ 
\textbf{Varying Definitions of Plagiarism}: Some cultures and instituitions promote collaboration as well as code borrowing so it is essential to define what plagiarism is in the context of this project. The tool should also be modifiable in its threshold for detecting plagiarism so instituitions can chnage it to their needs.


\section{Compliance Requirements}

In developing the enhanced plagiarism detection tool, it is imperative to address
various compliance requirements to ensure the tool operates legally, ethically,
and in alignment with industry standards. These requirements encompass legal
obligations related to data protection, intellectual property rights, and
adherence to educational policies, as well as compliance with established software
development and data security standards.

\subsection{Legal Requirements}

\begin{enumerate}
    \item \textbf{Data Protection and Privacy Laws}: The tool will process sensitive
    information, including students' code submissions, which may be considered personal
    data under Canadian privacy laws such as the \textit{Personal Information Protection 
    and Electronic Documents Act} (PIPEDA) at the federal level, and Ontario's \textit{Freedom of 
    Information and Protection of Privacy Act} (FIPPA) for public institutions. Compliance with these 
    laws requires:
    \begin{itemize}
        \item \textbf{Lawful Basis for Data Processing}: Ensuring that the collection and use of 
        personal information is authorized under PIPEDA or FIPPA, typically requiring consent from 
        students before processing their code or ensuring that processing is necessary for educational purposes.
        \item \textbf{Data Minimization and Purpose Limitation}: Collecting only the data
        necessary for plagiarism detection and using it solely for that purpose.
        \item \textbf{Transparency and Information Rights}: Informing students about how
        their data will be used, stored, and protected, and respecting their rights to
        access, correct, or withdraw their personal information.
        \item \textbf{Security Measures}: Implementing appropriate technical and
        organizational measures to safeguard personal data against unauthorized access,
        loss, or disclosure, as required under PIPEDA and FIPPA.
    \end{itemize}

    \item \textbf{Intellectual Property Rights}: Under the \textit{Copyright Act} of Canada, 
    students typically hold the intellectual property rights to their original code. 
    The tool must:
    \begin{itemize}
        \item \textbf{Respect Ownership}: Use students' code exclusively for plagiarism
        detection without unauthorized distribution or reproduction.
        \item \textbf{Establish Clear Terms}: Provide clear terms of service or agreements
        outlining how the code will be used, ensuring students are aware and consent to
        these terms.
        \item \textbf{Avoid Infringement}: Ensure that any storage or processing of code
        does not violate the \textit{Copyright Act} or institutional policies.
    \end{itemize}

    \item \textbf{Academic Integrity Policies}: The tool must align with the academic
    integrity and misconduct policies of Canadian educational institutions by:
    \begin{itemize}
        \item \textbf{Supporting Fair Evaluation}: Assisting educators in identifying
        potential plagiarism accurately without bias.
        \item \textbf{Due Process}: Ensuring that students have the opportunity to respond
        to plagiarism accusations, with results from the tool serving as part of a broader
        investigation rather than definitive proof.
        \item \textbf{Confidentiality}: Maintaining the confidentiality of students' work
        and any findings related to plagiarism investigations.
    \end{itemize}
\end{enumerate}

\subsection{Standards Compliance Requirements}

\begin{enumerate}
    \item \textbf{Software Development Standards}: Adherence to recognized software development practices is essential for ensuring quality and maintainability.
        \begin{itemize}
            \item \textbf{SOLID Principles}: The project will follow SOLID principles—Single Responsibility, 
            Open/Closed, Liskov Substitution, Interface Segregation, and Dependency Inversion—to promote clean,
             maintainable, and scalable code.
            \item \textbf{Documentation and Testing}: Thorough documentation will be maintained throughout 
            development, and rigorous testing will be conducted to validate the tool's performance and reliability.
        \end{itemize}



    \item \textbf{Data Security Standards}: Protecting sensitive data is a priority, and although full 
    compliance with industry security standards such as ISO/IEC 27001 may not be feasible for a student 
    capstone project, we will take measures to ensure data security.
        \begin{itemize}
            \item \textbf{OWASP Guidelines}: Basic security measures will be implemented in line with the 
            Open Web Application Security Project (OWASP) guidelines to mitigate common vulnerabilities such 
            as injection attacks and unauthorized access.
            \item \textbf{Secure Database Storage}: All data will be securely stored in a trusted cloud 
            database service (e.g., AWS), utilizing built-in security features such as encryption at rest 
            and in transit, to protect sensitive user information.
        \end{itemize}


    \item \textbf{Accessibility Standards}: While the tool may not be fully accessible for users with disabilities, 
    it will be designed to accommodate users regardless of their computer specifications. All computational tasks 
    will be handled on our servers, ensuring consistent performance across a variety of devices, including those 
    with lower processing power or outdated hardware.

    \item \textbf{Ethical AI and Machine Learning Standards}: As the tool leverages AI
    technologies, it must adhere to ethical standards in AI development.
    \begin{itemize}
        \item \textbf{Transparency and Explainability}: Ensuring that the AI models used
        are transparent in their operation and that their decision-making processes can be
        explained to users.
        \item \textbf{Fairness and Non-Discrimination}: Preventing biases in the AI models
        that could unfairly target or disadvantage any group of students. Ensuring that names
        and other potentially discriminatory information are not used in the detection process.
    \end{itemize}

    \item \textbf{Data Handling and Retention Policies}: Establishing clear policies for
    how data is managed throughout its lifecycle.
    \begin{itemize}
        \item \textbf{Retention Limits}: Defining how long code submissions and related
        data will be stored, in compliance with PIPEDA, FIPPA, and institutional policies.
        \item \textbf{Secure Disposal}: Implementing procedures for the secure deletion or
        anonymization of data that is no longer needed.
        \item \textbf{Audit and Compliance}: Regularly auditing data handling practices to
        ensure ongoing compliance with all relevant laws and standards.
    \end{itemize}
\end{enumerate}

By meticulously addressing these legal and standards compliance requirements, the
project not only safeguards the rights and interests of all stakeholders but also
enhances the credibility and trustworthiness of the plagiarism detection tool. Ensuring
compliance is fundamental to the tool's success and its acceptance by educational
institutions, educators, and students alike.


\section{Open Issues}
\lips

\section{Off-the-Shelf Solutions}
\subsection{Ready-Made Products}

There are many ready-made tools that aim to detect source-code level plagiarism, the most well-known of which being \href{https://theory.stanford.edu/~aiken/moss/}{MOSS}. MOSS is most commonly used by professors.
There are also a handful of open-source alternatives, including: \href{https://github.com/jplag/JPlag}{JPlag}, \href{https://dickgrune.com/Programs/similarity_tester/}{SIM}, \href{https://warwick.ac.uk/fac/sci/dcs/research/ias/software/sherlock/}{Sherlock}, and \href{https://www.cs.hut.fi/Software/Plaggie/}{Plaggie}.
Most of them support checking of multiple languages and use a variety of techniques to improve detection rates. These tools are relatively old and are not all actively developed.

\subsection{Reusable Components}

JPlag uses ANTLR 4 as a parser generator for many of its supported languages. For cross-language support, our tool can reuse JPlag's ANTLR grammar files to create language frontend parsers for each language we choose to support. Using a parser generator with pre-existing grammar files would reduce development time significantly, since the alternative would entail writing a custom parser for each supported language. By using ANTLR and JPlag's grammar files, we could feasibly support many source languages as opposed to just one, which would most likely be python (our product will be written in python, and python is capable of parsing it's own syntax tree).

\subsection{Products That Can Be Copied}

The primary inspiration for our product is MOSS. Our product, similar to many others, will copy the general data pipeline of input source code. Specifically, after reading an input source code file, plagiarism checkers typically have parsing, tokenizing, and normalizing steps. This is followed by some analysis on the normalized text - \href{https://theory.stanford.edu/~aiken/publications/papers/sigmod03.pdf}{MOSS uses "Winnowing"}, an algorithm that produces local fingerprints in a piece of text.

To reduce development time, we plan to copy the first step (the text preprocessing as described above) of the data pipeline implemented in MOSS. This kind of text normalization is commonly studied and there are many resources that explain implementation details.

\section{New Problems}
\subsection{Effects on the Current Environment}
\lips
\subsection{Effects on the Installed Systems}
\lips
\subsection{Potential User Problems}
\lips
\subsection{Limitations in the Anticipated Implementation Environment That May
Inhibit the New Product}
\lips
\subsection{Follow-Up Problems}
\lips

\section{Tasks}
\subsection{Project Planning}
\lips
\subsection{Planning of the Development Phases}
\lips

\section{Migration to the New Product}
\subsection{Requirements for Migration to the New Product}
The migration to the new code plagiarism detection system must be carefully planned and executed to ensure smooth adoption by academic institutions. The following requirements should be addressed:
\begin{itemize}
    \item \textbf{User Training and Support}: Provide comprehensive documentation and training materials for professors, system administrators, and students to familiarize them with the new system. This includes tutorials on how to upload code, interpret results, and resolve flagged cases.
    \item \textbf{Phased Rollout}: Implement a phased migration plan, starting with pilot tests in a controlled environment (e.g., one course or department) before full-scale implementation across the institution.
    \item \textbf{Data Security Compliance}: Ensure that all data migrations comply with data protection regulations, such as Canada's Privacy Act. Secure student data and ensure that no sensitive information is exposed during migration.
    \item \textbf{System Downtime Minimization}: Plan the migration to minimize downtime and disruption to academic workflows. Ideally, the transition should occur during a break period, when student and faculty activity is low.
\end{itemize}
\subsection{Data That Has to be Modified or Translated for the New System}
For the migration to the new plagiarism detection system, certain data from the legacy systems must be modified or translated to ensure compatibility:
\begin{itemize}
    \item \textbf{Code Submissions}: Legacy code submissions must be translated into a format that the new system can process, especially if the old system uses proprietary formats or different programming language encoding.
    \item \textbf{Plagiarism Reports}: Historical plagiarism reports and similarity scores from the legacy system need to be reformatted to align with the structure of the new system's reporting. This includes recalculating similarity scores if necessary.
    \item \textbf{User Data and Permissions}: Any existing user data, including professor, student, and administrator accounts, needs to be transferred to the new system. This includes roles, permissions, and access levels.
    \item \textbf{Configuration Data}: Settings from the old system, such as threshold scores, course configurations, and institution-specific policies, must be mapped and adjusted to fit the new system’s configuration parameters.
    \item \textbf{Metadata and Logs}: Metadata (e.g., submission timestamps, course IDs) and system logs related to prior plagiarism checks should be preserved and transferred, ensuring transparency and continuity.
\end{itemize}

\section{Costs}
The costs associated with this project come from several different parts of the project.
\begin{itemize}
    \item Data must be acquired before training the model. The data required to
    train the model can cost money. However, the team intends to automate
    processes to acquire data, and thus there is no charge incurred. An unknown
    amount of money will be needed for data if the team's method of acuiring
    data fails.
    \item In the training and testing phase, the model will require hardware to
    be trained on. The team intends to use Google Co-lab and leverage the
    hardware provided by their cloud platform. This will cost approximately 30
    dollars for the required computation. However, if more training and testing
    is required, more Google compute units will be used, costing more money. An
    upper limit of 150 dollars is set, which is 5 times more than the current
    guess. 
    \item The front end will need to be hosted somewhere. However, free
    alternatives exist, thus this will have no cost incurred.

\end{itemize}
In total, the project should only cost approximately 30 dollars. The cost is
subject to change, and can increase/decrease depending on the amount of data
needed, and the how much Google's cloud hardware is used.

\section{User Documentation and Training}
\subsection{User Documentation Requirements}
\lips
\subsection{Training Requirements}
\lips

\section{Waiting Room}
\lips

\section{Ideas for Solution}
\lips

\newpage{}
\section*{Appendix --- Reflection}

The information in this section will be used to evaluate the team members on the
graduate attribute of Lifelong Learning.  Please answer the following questions:

\begin{enumerate}
  \item What knowledge and skills will the team collectively need to acquire to
  successfully complete this capstone project?  Examples of possible knowledge
  to acquire include domain specific knowledge from the domain of your
  application, or software engineering knowledge, mechatronics knowledge or
  computer science knowledge.  Skills may be related to technology, or writing,
  or presentation, or team management, etc.  You should look to identify at
  least one item for each team member.
  \item For each of the knowledge areas and skills identified in the previous
  question, what are at least two approaches to acquiring the knowledge or
  mastering the skill?  Of the identified approaches, which will each team
  member pursue, and why did they make this choice?
\end{enumerate}

\end{document}