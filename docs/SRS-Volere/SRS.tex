% THIS DOCUMENT IS FOLLOWS THE VOLERE TEMPLATE BY Suzanne Robertson and James Robertson
% ONLY THE SECTION HEADINGS ARE PROVIDED
%
% Initial draft from https://github.com/Dieblich/volere
%
% Risks are removed because they are covered by the Hazard Analysis
\documentclass[12pt]{article}

\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{hyperref}
\usepackage{longtable}
\hypersetup{
    bookmarks=true,         % show bookmarks bar?
      colorlinks=true,      % false: boxed links; true: colored links
    linkcolor=red,          % color of internal links (change box color with linkbordercolor)
    citecolor=green,        % color of links to bibliography
    filecolor=magenta,      % color of file links
    urlcolor=cyan           % color of external links
}

\renewcommand{\labelenumii}{\arabic{enumi}.\arabic{enumii}}
\renewcommand{\labelenumiii}{\arabic{enumi}.\arabic{enumii}.\arabic{enumiii}}
\renewcommand{\labelenumiv}{\arabic{enumi}.\arabic{enumii}.\arabic{enumiii}.\arabic{enumiv}}
\newcommand{\lips}{\textit{Insert your content here.}}

\input{../Comments}
\input{../Common}

\begin{document}

\title{Software Requirements Specification for \progname: Code Plagiarism Detector} 
\author{\authname}
\date{\today}
	
\maketitle

~\newpage

\pagenumbering{roman}

\tableofcontents

~\newpage

\section*{Revision History}

\begin{tabularx}{\textwidth}{p{3cm}p{2cm}X}
\toprule {\textbf{Date}} & {\textbf{Version}} & {\textbf{Notes}}\\
\midrule
October 9 & 1.0 & First iteration of complete document\\
% Date 2 & 1.1 & Notes\\
\bottomrule
\end{tabularx}

~\\

~\newpage
\section{Purpose of the Project}
\subsection{User Business (Cases)}

The purpose of the project is first and foremost illustrated through the 
fulfillment of use cases our stakeholders are interested. These use cases
and associated stakeholder interest are stated below.

\begin{enumerate}

    \item \textbf{Plagiarism Assessment}

    \begin{enumerate}

        \item user selects option from main UI screen to provide dataset for scanning

        \item user is prompted to provide dataset
        \begin{enumerate}
            \item user inserts data from their computer

            \item user cancels and is sent back to main UI screen (1.1 continues)
        \end{enumerate}

        \item user initiates analysis and progress indicator appears

        \begin{enumerate}
            \item error occurs during analysis and user is prompted to restart or cancels

            \begin{enumerate}
                \item user selects to restart analysis (1.3 continues)

                \item user cancels and returns to main UI (1.1 continues)

            \end{enumerate}

            \item progress bar completes and success message is displated (proceeds to 1.4)
        \end{enumerate}

        \item system provides results in a UI display accompanied by option to download result or return to main UI

        \begin{enumerate}
            \item user selects download option

            \begin{enumerate}
                \item download fails accompanied by error message (continues from 1.4)

                \item download succeeds and system provides dialogue to check for download after which user returns to main UI

            \end{enumerate}
        \end{enumerate}
        
        \item system has provided result of analysis
        
    \end{enumerate}

    Stakeholder Interest: meets desire to gain direction on whether or not plagiarism has occurred within their environment

    \newpage

    \item \textbf{Plagiarism Detector Adjustment}

    \begin{enumerate}
        \item user selects option from main UI to open settings for app

        \item user can adjust threshold used for detection, and possibly other components such as version of model architecture used (not confirmed at the moment)

        \item user saves settings through UI provided option

        \begin{enumerate}

            \item System displays setting changes are saved, displaying success message, prompting whether user desires to continue or not

            \begin{enumerate}

                \item user selects to continue (2.2 continues)

                \item user selects to finish (2.4 continues)

            \end{enumerate}

            \item System displays setting changes did not save and provides dialogue to determine error, giving option to try again or return to main UI 

            \begin{enumerate}

                \item user selects to try again (2.2 continues)

                \item user selects to return to main UI (2.1 continues)

            \end{enumerate}
        
        \end{enumerate}

        \item system maintains settings and applies them for functions until application restart

    \end{enumerate}

    Stakeholder Interest: allows all stakeholders to cater app more towards their particular problem.

\end{enumerate}
\subsection{Goals of the Project}

\begin{center}
    % \hspace*{-1cm}
    \begin{longtable}{ | p{3cm} | p{6cm} | p{6cm} | }
    \hline
    Goal & Explanation & Reason \\
    \hline
    Ease of Use & Detector has an intuitive way to insert data and obtain results &
    This application is expected to be used as a secondary tool for
    teachers/professors when administering assignments. It should not require
    in-depth learning, or it will be too inconvenient as an assistant tool for
    detecting plagiarism. (Measured by actions to complete analysis)\\
    \hline
    Clarity of Output & Detector explains how to interpret outputs clearly, leaving
    no ambiguity in whether plagiarism is suspected & If the user does not
    comprehend the output, it may result in unjust accusations or undetected
    plagiarism. (Measured by lines of description or number of users who correctly
    interpret output)\\
    \hline
    Real-Time Processing & The detector computes results on a dataset of code
    snippets quickly, enabling professors to incorporate them into evaluations &
    Since multiple assignments are administered over several weeks, the detector
    must be fast enough to be realistic for daily use. (Measured by execution
    time)\\
    \hline
    False Positive Accuracy & The detector prioritizes minimizing false positives over
    false negatives & In this case, a false positive could cause harm to an innocent
    student, while a false negative allows a violation to go unnoticed. The focus is
    on protecting innocent students. (Measured by false positives and negatives
    using recall, precision, etc.)\\
    \hline
    Ethically Sourced Data & The detector uses only data that openly discloses its 
    origins and all data used for the detector is stated for all to see. & In 
    modern ML development, it has become a hot topic for how models get their data.
    This is because many modern models have used datasets that contain information
    that was taken from individuals without consent (such as pieces of art). It is
    important to our team to make it clear this is not precedent and that 
    individuals should have clear consent in being used for training models. 
    (Measured by having accreditation for datasets involved in training)\\
    \hline
    \end{longtable}
    \end{center}
    
    
    \begin{center}
      \hspace*{-1cm}
      \begin{tabular}{ 
        | p{3cm} 
        | p{6cm} 
        | p{6cm} | }
      \hline
       Stretch Goal & 
      Explanation & 
      Reason \\
      \hline
      Online Learning & 
      Provide ability for user to train model on their own datasets. & 
      Without a sufficiently large amount of data to train on (more than will be seen over the duration of 8 months), the model will be biased to a degree and not as widely applicable to different sets of code. If the detector is given the ability to be trained by the user, they can better customize it for their own needs (measure is whether or not the user can change conduct training)\\
      \hline
      Language Agnostic & 
      The detector can analyze code from a multitude of languages & 
      Having a detector that can draw patterns across different languages will make it adoptable by a wider set of professors who may conduct courses in less popular languages that our detector may have not dealt with at all before. If the detector is restrained to languages such as python or java, we will alienate some of our primary stakeholders.\\
      \hline
      \end{tabular}
      \end{center}

\section{Stakeholders}

\subsection{Client}
The primary clients for this project are the computing and software departments
of academic institutions, and code competition administrators. These clients
seek an advanced plagiarism detection system that overcomes the limitations of
existing tools like MOSS. In academic settings, the system will help maintain
academic integrity, while in code competitions, it will ensure fair play by
preventing plagiarism among participants.

\subsection{Customer}
The primary customers for this project are professors, course instructors, and
code competition organizers. Professors and instructors will use the system to
evaluate student submissions to identify plagiarism, while competition
organizers will ensure that all participants submit original code. 

\subsection{Other Stakeholders}
Other stakeholders include:
\begin{itemize}
    \item Students: Indirectly affected, as their work will be evaluated by this
    system, and it is important to ensure that students don't get falsely accused
    of plagiarism.
    \item Competition Participants: In coding competitions, the participants
    rely on the system to ensure the competition they participate in is fair.
\end{itemize}

\subsection{Hands-On Users of the Project}
The hands-on users are the professors, teaching assistants, and code competition
organizers who will directly interact with the system. They will use it to
upload code submissions, compare entries, and review plagiarism reports.

\subsection{Personas}
\begin{itemize}
    \item Professor: Dr.\ Onjama Wembo - A computer science professor who
    frequently assigns coding tasks and reviews student submissions.
    \item Student: John Johnson - An honest computer science student who
    expects the system to verify their work as valid and unplagiarised.
    \item Competition Organizer: Sung Yuhee - A competition organizer who
    uses the system to ensure participants submit original work to ensure fair
    play in the competition.
    \item Competition Participant: Giorno Capio - A competition participant
    aiming for a top score in the competition, who is hoping the system does not
    misclassify their work with someone elses who may have similar code.
\end{itemize}

\subsection{Priorities Assigned to Users}
\begin{itemize}
    \item High Priority: Professors, competition organizers, and instructors -
    They rely on the system to evaluate submissions to ensure integrity
    \item Low Priority: Students and competition participants - They are not the
    direct users of the system but rely on it for correct evaluations
\end{itemize}

\subsection{User Participation}
User participation is essential for the development and testing of the system.
Professors will provide feedback during development and testing to ensure the
system meets their needs. Regular feedback will help improve the system's
accuracy and reliability.

\subsection{Maintenance Users and Service Technicians}
If possible, system administrators and IT staff will maintain the system. They
will troubleshoot issues to keep the system functional, as well as oversee
updates to the system.

% EXTERNALLY IMPOSED
% GIVE RATIONALE FOR EACH CONSTRAINT
% - RATIONALE MAKES SENSE FOR THE PROJECT
% CONSTRAINTS ARE WHEN "HOW" IS IMPOSED BY EXTERNAL CONSIDERATIONS
% NON-ABSTRACT REQUIREMENTS ("HOW") ARE CONSTRAINTS

\section{Mandated Constraints}
\subsection{Solution Constraints}
\begin{table}[h!]
    \centering
    \begin{tabular}{| p{0.475\linewidth} | p{0.475\linewidth} |}
    \hline
    \textbf{Constraint}   & \textbf{Rationale} \\
    \hline
    Our product shall follow a zero data retention policy. &
    We should comply with privacy laws regarding storage of sensitive information. \\
    \hline
    \end{tabular}
    % \caption{}
\end{table}


\subsection{Implementation Environment of the Current System}
\begin{table}[h!]
    \centering
    \begin{tabular}{| p{0.475\linewidth} | p{0.475\linewidth} |}
    \hline
    \textbf{Constraint}   & \textbf{Rationale} \\
    \hline
    The application code should run on both Windows and Linux. &
    Users of our product who wish to host their own instance will be using a variety of server hardware providers, including Microsoft Azure and Amazon AWS. \\
    \hline
    The user interface should be accessible via a web browser on a computer with an internet connection. &
    Users of our product will access the tool on their own personal computers, which are not powerful enough to run the tool offline. \\
    \hline
    \end{tabular}
    % \caption{}
\end{table}



\subsection{Partner or Collaborative Applications}
Our project will use Google Colab to train and tune our language models for the NLP component of our tool.
\begin{table}[h!]
    \centering
    \begin{tabular}{| p{0.475\linewidth} | p{0.475\linewidth} |}
    \hline
    \textbf{Constraint}   & \textbf{Rationale} \\
    \hline
    Usage of the Google Colab platform for training shall not exceed 100 compute units. &
    We will only purchase 100 compute units to stay within our project budget. \\
    \hline
    The training and tuning of our language models will be written in python. &
    Google Colab only supports python. \\
    \hline
    The number of training iterations of our language model will not exceed 1000. &
    The amount of computational power provided by Google Colab is the limiting factor in our training speed. \\
    \hline
    \end{tabular}
    % \caption{}
\end{table}

\subsection{Off-the-Shelf Software}
\begin{table}[h!]
    \centering
    \begin{tabular}{| p{0.475\linewidth} | p{0.475\linewidth} |}
    \hline
    \textbf{Constraint}   & \textbf{Rationale} \\
    \hline
    Any third-party code used in the project must be licensed under an open-source license that is compatible with the GPLv3 License. &
    Our project uses the GPLv3 license. \\
    \hline
    \end{tabular}
    % \caption{}
\end{table}

\subsection{Anticipated Workplace Environment}
% need a computer and a desk ??
% good internet
There are no constraints imposed upon us by the anticipated workplace environment.


\subsection{Schedule Constraints}
\begin{table}[h!]
    \centering
    \begin{tabular}{| p{0.475\linewidth} | p{0.475\linewidth} |}
    \hline
    \textbf{Constraint}   & \textbf{Rationale} \\
    \hline
    Training data for language models shall consist of pre-labelled datasets on the internet, or scraped from online programming contests results and labelled with an existing plagirism detection tool. &
    Given the schedule of the project, there is not enough time to source and label datasets by hand. \\
    \hline
    \end{tabular}
    % \caption{}
\end{table}


\subsection{Budget Constraints}
\begin{table}[h!]
    \centering
    \begin{tabular}{| p{0.475\linewidth} | p{0.475\linewidth} |}
    \hline
    \textbf{Constraint}   & \textbf{Rationale} \\
    \hline
    The cost of sourcing training data and training NLP models using cloud computers shall not exceed \$150 CAD. &
    We are students and we don't have a lot of money. \\
    \hline
    \end{tabular}
    % \caption{}
\end{table}


\subsection{Enterprise Constraints}
There are no enterprise constraints imposed upon our project.

\section{Naming Conventions and Terminology}
\subsection{Glossary of All Terms, Including Acronyms, Used by Stakeholders
involved in the Project}
\lips

\section{Relevant Facts And Assumptions}
\subsection{Relevant Facts}
\begin{itemize}
  \item The current standard for code plagiarism detection, MOSS, primarily relies on token matching and syntax-based comparison. This method lacks the ability to detect deeper semantic similarities in code.
  \item NLP techniques have advanced significantly in recent years, enabling more accurate natural language understanding. These techniques can be adapted to understand the structure and semantics of code, which could enhance plagiarism detection systems.
  \item There is a growing need for a plagiarism detection system that accounts for sophisticated plagiarism techniques, such as variable renaming, code restructuring, and adding non-functional code.
  \item Academic institutions are increasingly concerned with the fairness and accuracy of plagiarism detection systems to avoid penalizing students unfairly, especially with the rising prevalence of online and remote learning.
\end{itemize}
\subsection{Business Rules}
\begin{itemize}
  \item The system must ensure compliance with data protection regulations by following a zero data retention policy.
  \item The similarity threshold for flagging plagiarism should be customizable by the institution or professor, allowing flexibility based on course policies.
  \item False positives (e.g., common code patterns) should be minimized, with options for professors to override flagged instances and manually validate the results.
  \item The system must be scalable to accommodate large datasets and multiple users submitting code for comparison at the same time.
\end{itemize}
\subsection{Assumptions}
\begin{itemize}
  \item It is assumed that the academic institutions adopting this system have clear plagiarism policies and can provide a threshold score that reflects their definitions of plagiarism.
  \item It is assumed that the code samples provided for comparison are original and not previously processed by other plagiarism detection systems, ensuring that the results reflect real-time analysis.
  \item It is assumed that professors and administrators will review flagged cases manually to confirm plagiarism before taking any disciplinary action.
  \item It is assumed that students will not have access to the internal workings of the plagiarism detection algorithm, preventing them from finding potential loopholes to bypass detection.
  \item Software will be used only in Canada, and the legal and ethical considerations of this country will be taken into account during development.
\end{itemize}

\section{The Scope of the Work}
\subsection{The Current Situation}
The current code plagiarism dtection tools such as MOSS rely on tokenization and syntax-level comparisons. Although effective
in detecting direct copies or slight variations, they struggle when faced with techniques such as adding redundant code which
allows the user to completely bypass detection while still plagiarizing the underlying logic and structure of the code.

Additionally, MOSS does not take into account for the complexity or intent behind the code, leading to issues such as false
positives for common programming patterns. This creates a gap for more advanced tools capable of understanding the semantic 
meaning of code to more accurately detect plagiarism.
\subsection{The Context of the Work}
Our project aims to address these gaps by incorporating Natural Language Processing (NLP) and machine learning techniques
which will be leveraged to improve the accuracy of detecting copied code. The context of the work is within academic institutions,
where the integrity of student work is aparmount and our tool will be used by professors to ensure a fair grading process
while also supporting students in understanding the ethical use of code.
\subsection{Work Partitioning}
\begin{itemize}
  \item \textbf{Research and Design}: Conduct research on current plagiarism detection systems and state-of-the-art NLP techniques applicable to code plagiarism.
  
  \item \textbf{Data Collection}: Gather a dataset of code snippets, including both plagiarized and original works, to train and test the model.
  
  \item \textbf{Model Development}: Develop the NLP-based model capable of understanding the semantic meaning of code. This may involve exploring techniques like abstract syntax trees (ASTs), vector embeddings, or other representations of code that retain semantic meaning.
  
  \item \textbf{System Integration}: Build the system to take code as input, run through the developed model, and output a similarity score with appropriate thresholds.
  
  \item \textbf{Testing and Validation}: Test the system with various code samples to validate its performance and accuracy compared to traditional systems like MOSS. This will also test whether our method produces any false positives.
  
  \item \textbf{Documentation and Deployment}: Document the system architecture, the model, and the results. Deploy the system for use within academic settings.
\end{itemize}
\subsection{Specifying a Business Use Case (BUC)}

\textbf{Business Use Case:} Automated Code Plagiarism Detection for Academic Institutions

\begin{itemize}
    \item \textbf{Actors:} Professors, Students, System Administrators
    \item \textbf{Trigger:} A professor or system administrator uploads multiple code submissions for plagiarism detection in a course assignment.
\end{itemize}

\textbf{Main Success Scenario}
\begin{enumerate}
    \item The system ingests the uploaded code submissions.
    \item The system processes each code snippet using the NLP model to generate semantic representations of the code.
    \item The system compares the representations to detect plagiarism, taking into account code similarity beyond syntax or token matching.
    \item The system outputs a similarity score for each comparison, with thresholds indicating whether plagiarism is suspected.
    \item The professor reviews the similarity scores and flags any suspicious cases for further investigation.
    \item The system generates a report summarizing the findings for the professor’s review.
\end{enumerate}

\textbf{Extensions}
\begin{itemize}
    \item If the system detects false positives (common programming patterns being flagged as plagiarism), the professor can override the result.
    \item If new sophisticated plagiarism techniques are detected, the system can update its learning algorithms to improve accuracy over time.
\end{itemize}

\section{Business Data Model and Data Dictionary}
\subsection{Business Data Model}
\lips
\subsection{Data Dictionary}
\lips

\section{The Scope of the Product}
\subsection{Product Boundary}
\lips
\subsection{Product Use Case Table}
\lips
\subsection{Individual Product Use Cases (PUC's)}
\lips

\section{Functional Requirements}
\subsection{Functional Requirements}
\begin{itemize}
    \item The system will take in code snippets as inputs
    \item The system must parse the input into a format that can be fed into a model for interpretation
    \item The system will leverage known natural language processing techniques to handle inputs
    \item The system will process the formatted input to provide a verdict on the presence of plagiarism as output
    \item The system must generate clear and concise outputs to indicate plagiarism
    \item The system's outputs should provide explanations on how to interpret output
    \item The system will allow users to create an account with an email and password
    \item The system will allow users to sign into their account with their email and password
    \item The system will send an email of the results in a .zip folder to a designated email address
    \item Users will be able to upload .zip folders of previous results to display the results on the interface
\end{itemize}

\section{Look and Feel Requirements}

\subsection{Appearance Requirements}
The user interface (UI) must adhere to the following appearance guidelines:
\begin{itemize}
    \item \textbf{Consistency}: The UI should maintain a uniform color palette, 
    font, and layout across all screens and elements. For instance, the primary 
    color is defined as blue (\#0047AB) for buttons, links, and headers, and 
    white (\#FFFFFF) for background areas.
    
    \item \textbf{Clarity}: All icons, buttons, and menus should be intuitive and 
    clearly identifiable. Hovering over icons will provide tooltips with a brief 
    description of their functionality.
    
    \item \textbf{Responsiveness}: The layout should adjust according to screen 
    size, ensuring the interface remains usable on a range of devices, including 
    desktops, tablets, and mobile phones.
\end{itemize}

\subsection{Style Requirements}
The style guidelines for the interface are as follows:
\begin{itemize}
    \item \textbf{Typography}: The font family used across the UI will be 
    \textit{Roboto}. Headers should use a 24px font size, body text should be 
    14px, and button text should be 16px.
    
    \item \textbf{Color Scheme}: Buttons and interactive elements should use the 
    primary color \#0047AB. Background areas will use \#F0F0F0, and error 
    messages will be highlighted in \#FF0000.
    
    \item \textbf{Button Styles}: All buttons should have rounded corners with 
    a radius of 5px. On hover, the button background will lighten by 20\%.
    
    \item \textbf{Spacing and Padding}: There should be at least 10px of padding 
    between elements and a margin of 20px around each section to maintain a clean 
    layout.
\end{itemize}


\section{Usability and Humanity Requirements}

\subsection{Ease of Use Requirements}
The system should be intuitive and simple to use for the target audience.
\begin{itemize}
    \item \textbf{Minimal Learning Curve}: Users should be able to complete tasks 
    with minimal instruction or training, taking at most 5 minutes from start 
    to finish. The interface must guide users intuitively through this process.
    
    \item \textbf{Task Efficiency}: Common tasks should be achievable in no more 
    than three clicks or interactions from the main screen.
    
    \item \textbf{Clear Navigation}: All navigation elements should be labeled 
    clearly and positioned consistently across different pages to avoid confusion.
\end{itemize}

\subsection{Personalization and Internationalization Requirements}
The system will support a customizable experience in the future, but users will 
not be able to modify key settings such as themes or layout preferences at launch.
\begin{itemize}
    \item \textbf{Future Customization Support}: Future updates will allow users 
    to modify settings such as themes and layouts to suit their personal preferences.
    
    \item \textbf{English Language Support}: The system will operate exclusively 
    in English, with all dates, currency, and numeric formats adhering to 
    English (US) standards.
\end{itemize}

\subsection{Learning Requirements}
The system should provide clear documentation and onboarding materials.
\begin{itemize}
    \item \textbf{Onboarding}: A guided onboarding process should be available 
    for new users, helping them understand the main features of the system 
    in under 5 minutes.
    
    \item \textbf{Help Documentation}: Detailed help documentation and tooltips 
    should be available for key features to reduce the need for external 
    assistance.
\end{itemize}

\subsection{Understandability and Politeness Requirements}
The system should use clear language and maintain a polite tone in all 
interactions with users.
\begin{itemize}
    \item \textbf{Clear Language}: All messages and labels should be in simple, 
    everyday language to ensure clarity for users of different levels of 
    technical expertise.
    
    \item \textbf{Politeness}: Error messages and prompts should be worded 
    politely and offer constructive guidance. Example error messages include:
    \begin{itemize}
        \item \textit{“Oops! Something went wrong. Please try again or contact 
        support if the issue persists.”}
        \item \textit{“We're sorry, but the file you uploaded is not supported. 
        Please upload a .py file.”}
    \end{itemize}
\end{itemize}

\subsection{Accessibility Requirements}
Due to time constraints, the system will not be fully accessible at launch. But this can be a future goal.

\section{Performance Requirements}
\subsection{Speed and Latency Requirements}
\begin{itemize}
    \item The system should process the inputs and provide results in under one minute 
    \item The system must notify users if processing surpasses one minute
\end{itemize}
\subsection{Safety-Critical Requirements}
\begin{itemize}
    \item The system must avoid false positives to protect students from wrongful accusations. 
    \item A manual override option for professors must exist to prevent automatic accusations solely based on the model.
\end{itemize}
\subsection{Precision or Accuracy Requirements}
\begin{itemize}
    \item The system should have an accuracy rate of at least 90\% for identifying plagiarized content.
    \item The false positive rate (incorrectly flagged plagiarism cases) must be kept below 5\%.
\end{itemize}
\subsection{Robustness or Fault-Tolerance Requirements}
\begin{itemize}
    \item The system will not crash in the case of a malformed input, and will instead issue an error message to the user.
\end{itemize}
\subsection{Capacity Requirements}
\begin{itemize}
    \item The system should be able to handle batches of inputs without significant delays.
    \item The system should be able to handle batches of inputs without the total processing time exceeding 60 seconds.
\end{itemize}
\subsection{Scalability or Extensibility Requirements}
\begin{itemize}
    \item The system should be designed in a way such that adding support for new file types or coding languages should not impede with current functionality
\end{itemize}
\subsection{Longevity Requirements}
\begin{itemize}
    \item Backwards compatibility must be maintained when new features are introduced
    \item The system should be designed such that the natural language processing part can be changed in accordance to new research in the field.
\end{itemize}

\section{Operational and Environmental Requirements}
\subsection{Expected Physical Environment}
\lips
\subsection{Wider Environment Requirements}
\lips
\subsection{Requirements for Interfacing with Adjacent Systems}
\lips
\subsection{Productization Requirements}
\lips
\subsection{Release Requirements}
\lips

\section{Maintainability and Support Requirements}
\subsection{Maintenance Requirements}
\begin{itemize}
    \item \textbf{Versioning}: keep track of and store model versions to allow
     switches between experimental models and previous versions (metric is 
     version history exists).

    Justification: Gives ability to work on separate model architectures to try 
    improvements in different directions as well as rollback on model releases 
    if something goes wrong as well as provide experimental releases.
    
    \item \textbf{Metric Reports}: every model release shall be accompanied by 
    a report of metrics decided upon to track model performance (metric is 
    report exists).

    Justification: Gives clarity whether model is being improved or not and what
     specific changes may be damaging the model. Will allow model health and 
     performance to be tracked and maintained over time.

    \item \textbf{Issue Tracking}: every bug should be registered in an issue 
    tracking system (metric is bugs existing as issues). 

    Justification: Brings attention to what bugs have been resolved and which 
    ones still require work.
    
\end{itemize}
\subsection{Supportability Requirements}
\begin{itemize}
    \item \textbf{Documentation}: provide concise (max 30 lines) comments on 
    all apis and algorithms used in code base. This will allow others to 
    comprehend what sections may need updates or bug fixes (metric is 
    comment exists at every piece of api code or algorithm)
    
    Justification: leaves no obfuscation in where somebody should adjust 
    code or update a component by clarifying what responsibility each area
     of code holds.

    \item \textbf{Logging }: provides a report of code components that 
    executed leading up to a crash whenever a crash occurs, so bugs can 
    be identified and fixes can be staged. (metric is a log with relevant 
    information about crash, such as a stack trace, is generated for user 
    to view when crash occurs).

    Justification: Almost 100\% necessary for effectively debugging issues in
     the code and giving the ability to support the model in the future for 
     people who aren't familiar with the code base.

    \item \textbf{Community Acknowledgement}: provide pathway for users to post
     or vote for requests/issues that should be addressed. (Metric is existence
      of said pathway, like email or github issues or forum).

    Justification: Will highlight to community what are current pain points 
    that should be prioritized and communication about how it is desired to 
    address them.

\end{itemize}
\subsection{Adaptability Requirements}
\begin{itemize}
    \item \textbf{Dataset Compatibility}: provide compatibility for at least 
    two data formats when it comes to training datasets (metric is data 
    formats that are accepted).

    Justification: will allow model to accommodate wider amount of datasets 
    and provides it better longevity in case either one of its data formats 
    becomes less popular.
    
    \item \textbf{Template Adherence}:  every model layer/component follows a 
    template. (metric is a template exists for all model layers/components and
     are upheld by said layers/components.)

    Justification - if somebody wishes to update the model with new 
    layers/components or modify existing ones, there will be a guide to make 
    the process straightforward and encourage those conducting the update to 
    follow through.

    \item \textbf{Modularity}:  every model layer/component can be treated as 
    an individual function. (metric is model layers/components can be fed an 
    input and produce an output which reflects only operations conducted within
     the layer/component).

    Justification - enables removal or substitution of individual model 
    layers/components which may be problematic or less efficient, similar to 
    how one may remove or substitute a function in a program, without having to
     overhaul a larger/more significant portion of the model architecture.


\end{itemize}

\section{Security Requirements}
\subsection{Access Requirements}
\begin{itemize}
    \item \textbf{Authentication}: The system shall require user authentication
    before allowing access to the tool. Only authenticated users can upload code for comparison.

    Justification - Users need to be identifiable so that they can receive their results via email and so that usage limits can be imposed upon them.
\end{itemize}

\subsection{Integrity Requirements}
Integrity requirements are outside the scope of this project. The system is designed to avoid storing any user data.
Since no data is retained, data integrity is not a concern.

\subsection{Privacy Requirements}
\begin{itemize}
    \item \textbf{Zero Data Retention}: The system shall retain no user-uploaded data beyond the immediate need of the task.
    Refer to section 17.2.5 for more information.

    Justification - This ensures that user privacy and protects sensitive academic work from being mishandled.

    \item \textbf{In Transit Encryption}: All data (including code snippets) shall be encrypted while being uploaded to or downloaded
    from the system using secure encryption protocols.

    Justification - Protecting user data during transmission ensures that it can't be intercepted by unauthorized third parties.
\end{itemize}

\subsection{Audit Requirements}
\begin{itemize}
    \item \textbf{In Transit Encryption}: The system shall log all user interactions and actions (such as authentication events, code uploads, and plagiarism checks) anonymously, without storing any user-uploaded code or sensitive data.

    Justification - While no user data is retained, logging system events and user actions provides a transparent way to track system usage and ensure accountability without violating the zero data retention policy.
\end{itemize}

\subsection{Immunity Requirements}
Immunity requirements are beyond the scope of this project. The system should not need to defend against external attacks
beyond the security measures already in place (e.g., authentication, encryption).
The focus of the project is on code plagiarism detection, and immunity against malicious actors is not a primary concern.

\section{Cultural Requirements}
\subsection{Cultural Requirements}
No major cultural requirements are identified for this project but some that could be taken into consideration are:\\ \\ 
\noindent \textbf{Data Privacy and Ethical Use}\\ 
\textbf{Student Privacy}: In some cultures and institutions, the handling of student work and data is highly regulated. Laws like the FIPPA mandate strict data privacy standards. The system should ensure that student data, including their code submissions, is securely handled, anonymized where possible, and not stored unnecessarily.
\\ \\
\noindent \textbf{Differences in Academic Integrity Norms}\\ 
\textbf{Varying Definitions of Plagiarism}: Some cultures and instituitions promote collaboration as well as code borrowing so it is essential to define what plagiarism is in the context of this project. The tool should also be modifiable in its threshold for detecting plagiarism so instituitions can chnage it to their needs.


\section{Compliance Requirements}

In developing the enhanced plagiarism detection tool, it is imperative to address
various compliance requirements to ensure the tool operates legally, ethically,
and in alignment with industry standards. These requirements encompass legal
obligations related to data protection, intellectual property rights, and
adherence to educational policies, as well as compliance with established software
development and data security standards.

\subsection{Legal Requirements}

\begin{enumerate}
    \item \textbf{Data Protection and Privacy Laws}: The tool will process sensitive
    information, including students' code submissions, which may be considered personal
    data under Canadian privacy laws such as the \textit{Personal Information Protection 
    and Electronic Documents Act} (PIPEDA) at the federal level, and Ontario's \textit{Freedom of 
    Information and Protection of Privacy Act} (FIPPA) for public institutions. Compliance with these 
    laws requires:
    \begin{itemize}
        \item \textbf{Lawful Basis for Data Processing}: Ensuring that the collection and use of 
        personal information is authorized under PIPEDA or FIPPA, typically requiring consent from 
        students before processing their code or ensuring that processing is necessary for educational purposes.
        \item \textbf{Data Minimization and Purpose Limitation}: Collecting only the data
        necessary for plagiarism detection and using it solely for that purpose.
        \item \textbf{Transparency and Information Rights}: Informing students about how
        their data will be used, stored, and protected, and respecting their rights to
        access, correct, or withdraw their personal information.
        \item \textbf{Security Measures}: Implementing appropriate technical and
        organizational measures to safeguard personal data against unauthorized access,
        loss, or disclosure, as required under PIPEDA and FIPPA.
    \end{itemize}

    \item \textbf{Intellectual Property Rights}: Under the \textit{Copyright Act} of Canada, 
    students typically hold the intellectual property rights to their original code. 
    The tool must:
    \begin{itemize}
        \item \textbf{Respect Ownership}: Use students' code exclusively for plagiarism
        detection without unauthorized distribution or reproduction.
        \item \textbf{Establish Clear Terms}: Provide clear terms of service or agreements
        outlining how the code will be used, ensuring students are aware and consent to
        these terms.
        \item \textbf{Avoid Infringement}: Ensure that any storage or processing of code
        does not violate the \textit{Copyright Act} or institutional policies.
    \end{itemize}

    \item \textbf{Academic Integrity Policies}: The tool must align with the academic
    integrity and misconduct policies of Canadian educational institutions by:
    \begin{itemize}
        \item \textbf{Supporting Fair Evaluation}: Assisting educators in identifying
        potential plagiarism accurately without bias.
        \item \textbf{Due Process}: Ensuring that students have the opportunity to respond
        to plagiarism accusations, with results from the tool serving as part of a broader
        investigation rather than definitive proof.
        \item \textbf{Confidentiality}: Maintaining the confidentiality of students' work
        and any findings related to plagiarism investigations.
    \end{itemize}
\end{enumerate}

\subsection{Standards Compliance Requirements}

\begin{enumerate}
    \item \textbf{Software Development Standards}: Adherence to recognized software development practices is essential for ensuring quality and maintainability.
        \begin{itemize}
            \item \textbf{SOLID Principles}: The project will follow SOLID principles—Single Responsibility, 
            Open/Closed, Liskov Substitution, Interface Segregation, and Dependency Inversion—to promote clean,
             maintainable, and scalable code.
            \item \textbf{Documentation and Testing}: Thorough documentation will be maintained throughout 
            development, and rigorous testing will be conducted to validate the tool's performance and reliability.
        \end{itemize}



    \item \textbf{Data Security Standards}: Protecting sensitive data is a priority, and although full 
    compliance with industry security standards such as ISO/IEC 27001 may not be feasible for a student 
    capstone project, we will take measures to ensure data security.
        \begin{itemize}
            \item \textbf{OWASP Guidelines}: Basic security measures will be implemented in line with the 
            Open Web Application Security Project (OWASP) guidelines to mitigate common vulnerabilities such 
            as injection attacks and unauthorized access.
        \end{itemize}


    \item \textbf{Accessibility Standards}: The tool will be designed to support basic accessibility features.
    \begin{itemize}
        \item \textbf{Screen Reader Support}: Key elements of the user interface will be made compatible with 
        screen readers to assist visually impaired users.
        \item \textbf{Alt Text for Images}: All images and non-text content will include descriptive alt text to 
        improve accessibility for users relying on assistive technologies.
        \item \textbf{Text Color Contrast}: The tool will ensure sufficient contrast between text and background 
        colors to improve readability for users with visual impairments or color blindness.
    \end{itemize}
        

    \item \textbf{Ethical AI and Machine Learning Standards}: As the tool leverages AI
    technologies, it must adhere to ethical standards in AI development.
    \begin{itemize}
        \item \textbf{Transparency and Explainability}: Ensuring that the AI models used
        are transparent in their operation and that their decision-making processes can be
        explained to users.
        \item \textbf{Fairness and Non-Discrimination}: Preventing biases in the AI models
        that could unfairly target or disadvantage any group of students. Ensuring that names
        and other potentially discriminatory information are not used in the detection process.
    \end{itemize}

    \item \textbf{Data Handling and Retention Policies}: Establishing clear policies for
    how data is managed throughout its lifecycle.
    \begin{itemize}
        \item \textbf{Zero Data Retention}: No user data will be retained beyond the immediate needs of the task.
        All user-uploaded data will be immediately loaded into memory and subsequently removed from disk as soon
        as the task is finished.
        \item \textbf{Secure Disposal}: Implementing procedures for the secure deletion or
        anonymization of data that is no longer needed.
        \item \textbf{Audit and Compliance}: Regularly auditing data handling practices to
        ensure ongoing compliance with all relevant laws and standards.
    \end{itemize}
\end{enumerate}

By meticulously addressing these legal and standards compliance requirements, the
project not only safeguards the rights and interests of all stakeholders but also
enhances the credibility and trustworthiness of the plagiarism detection tool. Ensuring
compliance is fundamental to the tool's success and its acceptance by educational
institutions, educators, and students alike.


\section{Open Issues}
\subsection{System Design Uncertainty}
\begin{itemize}
    \item How the integration of the Natural Language Processing (NLP) model with the code submission system will work. Such as choosing what NLP model to use, how to train it, and where to host it.
    \item Selecting the most appropriate techniques for semantic code analysis, such as Abstract Syntax Trees (ASTs) or vector embeddings.
    \item Deciding on how the model will handle false positives, especially common coding patterns, to avoid misclassification. Example. students using the same code snippets from a tutorial.
\end{itemize}

\subsection {Data Collection Challenges}
\begin{itemize}
    \item While the project mentions scraping datasets from online programming contests and using pre-labeled datasets, 
    there could be issues with data availability, quality, or ensuring that the data accurately reflects real-world usage.
\end{itemize}

\subsection {Scalability Concerns}
\begin{itemize}
    \item Ensuring the system remains performant when processing large batches of submissions within the 10-minute processing time goal. 
    Handling larger academic institutions with potentially thousands of submissions may challenge the current system's capacity requirements
    \item  Given the limited budget for cloud compute units, it may be challenging to balance performance improvements with cost constraints. 
    If training processes requires more resources than anticipated, costs could quickly escalate.
\end{itemize}
\section{Off-the-Shelf Solutions}
\subsection{Ready-Made Products}

There are many ready-made tools that aim to detect source-code level plagiarism, the most well-known of which being \href{https://theory.stanford.edu/~aiken/moss/}{MOSS}. MOSS is most commonly used by professors.
There are also a handful of open-source alternatives, including: \href{https://github.com/jplag/JPlag}{JPlag}, \href{https://dickgrune.com/Programs/similarity_tester/}{SIM}, \href{https://warwick.ac.uk/fac/sci/dcs/research/ias/software/sherlock/}{Sherlock}, and \href{https://www.cs.hut.fi/Software/Plaggie/}{Plaggie}.
Most of them support checking of multiple languages and use a variety of techniques to improve detection rates. These tools are relatively old and are not all actively developed.

\subsection{Reusable Components}

JPlag uses ANTLR 4 as a parser generator for many of its supported languages. For cross-language support, our tool can reuse JPlag's ANTLR grammar files to create language frontend parsers for each language we choose to support. Using a parser generator with pre-existing grammar files would reduce development time significantly, since the alternative would entail writing a custom parser for each supported language. By using ANTLR and JPlag's grammar files, we could feasibly support many source languages as opposed to just one, which would most likely be python (our product will be written in python, and python is capable of parsing it's own syntax tree).

\subsection{Products That Can Be Copied}

The primary inspiration for our product is MOSS. Our product, similar to many others, will copy the general data pipeline of input source code. Specifically, after reading an input source code file, plagiarism checkers typically have parsing, tokenizing, and normalizing steps. This is followed by some analysis on the normalized text - \href{https://theory.stanford.edu/~aiken/publications/papers/sigmod03.pdf}{MOSS uses "Winnowing"}, an algorithm that produces local fingerprints in a piece of text.

To reduce development time, we plan to copy the first step (the text preprocessing as described above) of the data pipeline implemented in MOSS. This kind of text normalization is commonly studied and there are many resources that explain implementation details.

\section{New Problems}
\subsection{Effects on the Current Environment}
\lips
\subsection{Effects on the Installed Systems}
\lips
\subsection{Potential User Problems}
\lips
\subsection{Limitations in the Anticipated Implementation Environment That May
Inhibit the New Product}
\lips
\subsection{Follow-Up Problems}
\lips

\section{Tasks}
\subsection{Project Planning}
\lips
\subsection{Planning of the Development Phases}
\lips

\section{Migration to the New Product}
\subsection{Requirements for Migration to the New Product}
The migration to the new code plagiarism detection system must be carefully planned and executed to ensure smooth adoption by academic institutions. The following requirements should be addressed:
\begin{itemize}
    \item \textbf{User Training and Support}: Provide comprehensive documentation and training materials for professors, system administrators, and students to familiarize them with the new system. This includes tutorials on how to upload code, interpret results, and resolve flagged cases.
    \item \textbf{Phased Rollout}: Implement a phased migration plan, starting with pilot tests in a controlled environment (e.g., one course or department) before full-scale implementation across the institution.
    \item \textbf{Data Security Compliance}: Ensure that all data migrations comply with data protection regulations, such as Canada's Privacy Act.
    \item \textbf{System Downtime Minimization}: Plan the migration to minimize downtime and disruption to academic workflows. Ideally, the transition should occur during a break period, when student and faculty activity is low.
\end{itemize}
\subsection{Data That Has to be Modified or Translated for the New System}
For the migration to the new plagiarism detection system, certain data from the legacy systems must be modified or translated to ensure compatibility:
\begin{itemize}
    \item \textbf{Code Submissions}: Legacy code submissions must be translated into a format that the new system can process, especially if the old system uses proprietary formats or different programming language encoding.
    \item \textbf{User Permissions}: Any user and administrator accounts need to be transferred to the new system. This includes roles, permissions, and access levels.
    \item \textbf{Configuration Data}: Settings from the old system, such as threshold scores, course configurations, and institution-specific policies, must be mapped and adjusted to fit the new system’s configuration parameters.
    \item \textbf{Metadata and Logs}: Metadata (e.g., anonymous submission timestamps, course IDs) and system logs related to prior plagiarism checks should be preserved and transferred, ensuring transparency and continuity.
\end{itemize}

\section{Costs}
The costs associated with this project come from several different parts of the project.
\begin{itemize}
    \item Data must be acquired before training the model. The data required to
    train the model can cost money. However, the team intends to automate
    processes to acquire data, and thus there is no charge incurred. An unknown
    amount of money will be needed for data if the team's method of acuiring
    data fails.
    \item In the training and testing phase, the model will require hardware to
    be trained on. The team intends to use Google Co-lab and leverage the
    hardware provided by their cloud platform. This will cost approximately 30
    dollars for the required computation. However, if more training and testing
    is required, more Google compute units will be used, costing more money. An
    upper limit of 150 dollars is set, which is 5 times more than the current
    guess. 
    \item The front end will need to be hosted somewhere. However, free
    alternatives exist, thus this will have no cost incurred.

\end{itemize}
In total, the project should only cost approximately 30 dollars. The cost is
subject to change, and can increase/decrease depending on the amount of data
needed, and the how much Google's cloud hardware is used.

\section{User Documentation and Training}
\subsection{User Documentation Requirements}
\lips
\subsection{Training Requirements}
\lips

\section{Waiting Room}
\lips

\section{Ideas for Solution}
\lips

\newpage{}
\section*{Appendix --- Reflection}

The information in this section will be used to evaluate the team members on the
graduate attribute of Lifelong Learning.  Please answer the following questions:

\begin{enumerate}
  \item What knowledge and skills will the team collectively need to acquire to
  successfully complete this capstone project?  Examples of possible knowledge
  to acquire include domain specific knowledge from the domain of your
  application, or software engineering knowledge, mechatronics knowledge or
  computer science knowledge.  Skills may be related to technology, or writing,
  or presentation, or team management, etc.  You should look to identify at
  least one item for each team member.
  \item For each of the knowledge areas and skills identified in the previous
  question, what are at least two approaches to acquiring the knowledge or
  mastering the skill?  Of the identified approaches, which will each team
  member pursue, and why did they make this choice?
\end{enumerate}

\end{document}